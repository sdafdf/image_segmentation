{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Miniconda3\\envs\\torch\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "mask_folder = \"F:\\\\PythonProject\\\\deep\\\\image_segmentation\\\\deep_learning\\\\data\\\\object_detection_segment\\\\segmentation\"\n",
    "data_folder = \"F:\\\\PythonProject\\\\deep\\\\image_segmentation\\\\deep_learning\\\\data\\\\object_detection_segment\\\\object_detection/\"\n",
    "sr_data_folder = \"../data/super_resolution/\"\n",
    "checkpoint = \"../chapter_three/net.pth\"\n",
    "sr_checkpoint = \"../datachapter_three/sr.pth\"\n",
    "\n",
    "batch_size = 8\n",
    "lr = 1e-3\n",
    "epoch_lr = [(20,0.01),(10,0.001),(10,0.0001)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 图像增强\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms import ToTensor, ToPILImage\n",
    "from sklearn.model_selection import train_test_split\n",
    "from glob import glob\n",
    "import os.path as osp\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "class Compose:\n",
    "    def __init__(self,transform_list):\n",
    "        self.transform_list = transform_list\n",
    "    def __call__(self, img, mask):\n",
    "        for transform in self.transform_list:\n",
    "            img, mask = transform(img,mask)\n",
    "        return img, mask\n",
    "\n",
    "class ToArraySegment:\n",
    "    def __call__(self,img,mask):\n",
    "        img = np.array(img)\n",
    "        mask = np.array(mask)\n",
    "        return img,mask\n",
    "\n",
    "class ToTensorSegment:\n",
    "    def __call__(self,img,mask):\n",
    "        return torch.from_numpy(img).permute(2,0,1).float()/255.,torch.from_numpy(mask).float()/255.\n",
    "\n",
    "class Resize:\n",
    "    def __init__(self,size=320):\n",
    "        self.size = size\n",
    "    def __call__(self,img,mask):\n",
    "        img = cv2.resize(img,(self.size,self.size))\n",
    "        mask = cv2.resize(mask,(self.size,self.size))\n",
    "        return img,mask\n",
    "\n",
    "class Expand:\n",
    "    def __call__(self,img,mask):\n",
    "        if np.random.randint(2):\n",
    "            width,_,channels = img.shape\n",
    "            ratio = np.random.uniform()\n",
    "            expand_img = np.zeros((int(width*(1+ratio)),int(width*(1+ratio)),channels))\n",
    "            expand_mask = np.zeros((int(width*(1+ratio)),int(width*(1+ratio))))\n",
    "            left = np.random.uniform(0,width*ratio)\n",
    "            top = np.random.uniform(0,width*ratio)\n",
    "            left = int(left)\n",
    "            top = int(top)\n",
    "            expand_img[top:top+width,left:left+width,:] = img\n",
    "            expand_mask[top:top+width,left:left+width]=mask\n",
    "\n",
    "            return expand_img,expand_mask\n",
    "        else:\n",
    "            return img,mask\n",
    "\n",
    "class MIrror:\n",
    "    def __call__(self,img,mask):\n",
    "        #在绝对坐标系啊运行\n",
    "        if np.random.randint(2):\n",
    "            width = img.shape[0]\n",
    "            img = img[:,::-1]\n",
    "            mask = mask[:,::-1]\n",
    "            return img,mask\n",
    "\n",
    "class TrainTrainsform:\n",
    "    def __init__(self,size=320):\n",
    "        self.size = size\n",
    "        self.augment = Compose([\n",
    "            ToArraySegment(),\n",
    "            MIrror(),\n",
    "            Expand(),\n",
    "            Resize(self.size),\n",
    "            ToTensorSegment()\n",
    "        ])\n",
    "    def __call__(self,img,mask):\n",
    "        img,mask = self.augment(img,mask)\n",
    "        return img,mask\n",
    "\n",
    "class TestTrainsform:\n",
    "    def __init__(self,size=320):\n",
    "        self.size = size\n",
    "        self.augment=Compose([\n",
    "            ToArraySegment(),\n",
    "            Resize(self.size),\n",
    "            ToTensorSegment()\n",
    "        ])\n",
    "\n",
    "    def __call__(self,img,mask):\n",
    "        img,mask = self.augment(img,mask)\n",
    "        return img,mask\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#数据加载\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms import ToTensor\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "import os \n",
    "from sklearn.model_selection import train_test_split\n",
    "#from transform import TrainTransform,TestTrainsform\n",
    "#from config import data_folder,mask_folder\n",
    "\n",
    "class SegmentationData(Dataset):\n",
    "    def __init__(self,data_folder=data_folder,mask_folder=mask_folder,subset=\"train\",trainsform=None):\n",
    "        super(SegmentationData,self).__init__()\n",
    "        img_paths = sorted(glob(os.path.join(data_folder,\"*.jpg\")))\n",
    "        mask_paths = sorted(glob(os.path.join(mask_folder,\"*.jpg\")))\n",
    "        for i in range(len(img_paths)):\n",
    "            assert os.path.basename(img_paths[i])==os.path.basename(mask_paths[i])\n",
    "        img_paths_train,img_paths_test,mask_paths_train,mask_paths_test = train_test_split(img_paths,mask_paths,test_size=0.2,random_state=20)\n",
    "        if subset==\"train\":\n",
    "            self.img_paths=img_paths_train\n",
    "            self.mask_paths = mask_paths_train\n",
    "        else:\n",
    "            self.img_paths = img_paths_test\n",
    "            self.mask_paths = mask_paths_test\n",
    "\n",
    "        self.transform = trainsform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.img_paths[index]).resize((224,224))\n",
    "        mask_path = self.mask_paths[index]\n",
    "        mask = Image.open(mask_path).resize((224,224)).convert(\"L\")\n",
    "        if self.transform:\n",
    "            image,mask = self.transform(image,mask)\n",
    "        else:\n",
    "            image,mask = ToTensor()(image),ToTensor()(mask)\n",
    "        return image,mask\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    topil = ToPILImage()\n",
    "    transform = TrainTrainsform()\n",
    "    data = SegmentationData(data_folder,mask_folder,transform)\n",
    "    image,mask = data[0]\n",
    "    image,mask = topil(image),topil(mask)\n",
    "    image.save(\"./sample.jpg\")\n",
    "    mask.save(\"./sample_mask.jpg\")\n",
    "    image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 320, 320])\n"
     ]
    }
   ],
   "source": [
    "#模型搭建\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self,in_channel,out_channel,kernel_size) -> None:\n",
    "        super(DecoderBlock,self).__init__()\n",
    "        #卷积\n",
    "        self.conv1 = nn.Conv2d(in_channel,in_channel//4,kernel_size,padding=1,bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(in_channel//4)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "\n",
    "        #反卷积\n",
    "        self.deconv = nn.ConvTranspose2d(\n",
    "            in_channel//4,\n",
    "            in_channel//4,\n",
    "            kernel_size=3,\n",
    "            stride=2,\n",
    "            padding=1,\n",
    "            output_padding=1,\n",
    "            bias=False\n",
    "        )\n",
    "        self.bn2 = nn.BatchNorm2d(in_channel//4)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "\n",
    "        #卷积\n",
    "        self.conv3 = nn.Conv2d(\n",
    "            in_channel//4,\n",
    "            out_channel,\n",
    "            kernel_size=kernel_size,\n",
    "            padding=1,\n",
    "            bias=False\n",
    "        )\n",
    "        self.bn3 = nn.BatchNorm2d(out_channel)\n",
    "        self.relu3 = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.relu1(self.bn1(self.conv1(x)))\n",
    "        x = self.relu2(self.bn2(self.deconv(x)))\n",
    "        x = self.relu3(self.bn3(self.conv3(x)))\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class ResNet18Unet(nn.Module):\n",
    "    def __init__(self,num_classes=2,pretrained=True) -> None:\n",
    "        super(ResNet18Unet,self).__init__()\n",
    "        base = resnet18(pretrained=pretrained)\n",
    "        self.firstconv = base.conv1\n",
    "        self.firstbn = base.bn1\n",
    "        self.firstrelu = base.relu\n",
    "        self.firstmaxpool = base.maxpool\n",
    "        self.encoder1 = base.layer1\n",
    "        self.encoder2 = base.layer2\n",
    "        self.encoder3 = base.layer3\n",
    "        self.encoder4 = base.layer4\n",
    "\n",
    "        out_channels = [64,128,256,512]\n",
    "        self.center = DecoderBlock(\n",
    "            in_channel=out_channels[3],\n",
    "            out_channel=out_channels[3],\n",
    "            kernel_size=3\n",
    "        )\n",
    "        self.decoder4 = DecoderBlock(\n",
    "            in_channel=out_channels[3]+out_channels[2],\n",
    "            out_channel=out_channels[2],\n",
    "            kernel_size=3\n",
    "        )\n",
    "        self.decoder3 = DecoderBlock(\n",
    "            in_channel=out_channels[2]+out_channels[1],\n",
    "            out_channel=out_channels[1],\n",
    "            kernel_size=3\n",
    "        )\n",
    "        self.decoder2 = DecoderBlock(\n",
    "            in_channel=out_channels[1]+out_channels[0],\n",
    "            out_channel=out_channels[0],\n",
    "            kernel_size=3\n",
    "        )\n",
    "        self.decoder1 = DecoderBlock(\n",
    "            in_channel=out_channels[0]+out_channels[0],\n",
    "            out_channel=out_channels[0],\n",
    "            kernel_size=3\n",
    "        )\n",
    "        self.finalconv = nn.Sequential(\n",
    "            nn.Conv2d(out_channels[0],32,3,padding=1,bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout2d(0.1,False),\n",
    "            nn.Conv2d(32,num_classes,1)\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.firstconv(x)\n",
    "        x = self.firstbn(x)\n",
    "        x = self.firstrelu(x)\n",
    "        x_ = self.firstmaxpool(x)\n",
    "\n",
    "        #Encoder\n",
    "        e1 = self.encoder1(x_)\n",
    "\n",
    "        e2 = self.encoder2(e1)\n",
    "        e3 = self.encoder3(e2)\n",
    "        e4 = self.encoder4(e3)\n",
    "\n",
    "        center = self.center(e4)\n",
    "\n",
    "        d4 = self.decoder4(torch.cat([center,e3],1))\n",
    "        d3 = self.decoder3(torch.cat([d4,e2],1))\n",
    "        d2 = self.decoder2(torch.cat([d3,e1],1))\n",
    "        d1 = self.decoder1(torch.cat([d2,x],1))\n",
    "\n",
    "        f = self.finalconv(d1)\n",
    "\n",
    "        return f\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    net = ResNet18Unet(pretrained=False)\n",
    "    img = torch.rand(1,3,320,320)\n",
    "    out = net(img)\n",
    "    print(out.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[[0.3020, 0.3020, 0.3020,  ..., 0.3804, 0.3804, 0.3804],\n",
      "          [0.3020, 0.3020, 0.3020,  ..., 0.3804, 0.3804, 0.3804],\n",
      "          [0.3059, 0.3059, 0.3059,  ..., 0.3843, 0.3843, 0.3843],\n",
      "          ...,\n",
      "          [0.3137, 0.3137, 0.3137,  ..., 0.3882, 0.3882, 0.3882],\n",
      "          [0.3137, 0.3137, 0.3137,  ..., 0.3882, 0.3882, 0.3882],\n",
      "          [0.3137, 0.3137, 0.3137,  ..., 0.3882, 0.3882, 0.3882]],\n",
      "\n",
      "         [[0.5647, 0.5647, 0.5647,  ..., 0.5608, 0.5608, 0.5608],\n",
      "          [0.5647, 0.5647, 0.5647,  ..., 0.5608, 0.5608, 0.5608],\n",
      "          [0.5686, 0.5686, 0.5686,  ..., 0.5647, 0.5647, 0.5647],\n",
      "          ...,\n",
      "          [0.5412, 0.5412, 0.5412,  ..., 0.5686, 0.5686, 0.5686],\n",
      "          [0.5412, 0.5412, 0.5412,  ..., 0.5686, 0.5686, 0.5686],\n",
      "          [0.5412, 0.5412, 0.5412,  ..., 0.5686, 0.5686, 0.5686]],\n",
      "\n",
      "         [[0.9216, 0.9216, 0.9216,  ..., 0.8980, 0.8980, 0.8980],\n",
      "          [0.9216, 0.9216, 0.9216,  ..., 0.8980, 0.8980, 0.8980],\n",
      "          [0.9255, 0.9255, 0.9255,  ..., 0.9020, 0.9020, 0.9020],\n",
      "          ...,\n",
      "          [0.8627, 0.8627, 0.8627,  ..., 0.8627, 0.8627, 0.8627],\n",
      "          [0.8627, 0.8627, 0.8627,  ..., 0.8627, 0.8627, 0.8627],\n",
      "          [0.8627, 0.8627, 0.8627,  ..., 0.8627, 0.8627, 0.8627]]],\n",
      "\n",
      "\n",
      "        [[[0.1882, 0.1882, 0.1882,  ..., 0.1725, 0.1725, 0.1725],\n",
      "          [0.1882, 0.1882, 0.1882,  ..., 0.1725, 0.1725, 0.1725],\n",
      "          [0.1922, 0.1922, 0.1922,  ..., 0.1765, 0.1765, 0.1765],\n",
      "          ...,\n",
      "          [0.9882, 0.9882, 0.9843,  ..., 0.8902, 0.8902, 0.8902],\n",
      "          [0.9882, 0.9882, 0.9843,  ..., 0.8902, 0.8902, 0.8902],\n",
      "          [0.9882, 0.9882, 0.9843,  ..., 0.8902, 0.8902, 0.8902]],\n",
      "\n",
      "         [[0.2000, 0.2000, 0.2000,  ..., 0.1843, 0.1843, 0.1843],\n",
      "          [0.2000, 0.2000, 0.2000,  ..., 0.1843, 0.1843, 0.1843],\n",
      "          [0.2039, 0.2039, 0.2039,  ..., 0.1882, 0.1882, 0.1882],\n",
      "          ...,\n",
      "          [0.9882, 0.9882, 0.9843,  ..., 0.8745, 0.8745, 0.8745],\n",
      "          [0.9882, 0.9882, 0.9843,  ..., 0.8745, 0.8745, 0.8745],\n",
      "          [0.9882, 0.9882, 0.9843,  ..., 0.8745, 0.8745, 0.8745]],\n",
      "\n",
      "         [[0.2275, 0.2275, 0.2275,  ..., 0.2039, 0.2039, 0.2039],\n",
      "          [0.2275, 0.2275, 0.2275,  ..., 0.2039, 0.2039, 0.2039],\n",
      "          [0.2314, 0.2314, 0.2314,  ..., 0.2078, 0.2078, 0.2078],\n",
      "          ...,\n",
      "          [0.9882, 0.9882, 0.9843,  ..., 0.8706, 0.8706, 0.8706],\n",
      "          [0.9882, 0.9882, 0.9843,  ..., 0.8706, 0.8706, 0.8706],\n",
      "          [0.9882, 0.9882, 0.9843,  ..., 0.8706, 0.8706, 0.8706]]],\n",
      "\n",
      "\n",
      "        [[[0.5961, 0.5961, 0.5961,  ..., 0.5961, 0.5961, 0.5961],\n",
      "          [0.6000, 0.6000, 0.6000,  ..., 0.5922, 0.5922, 0.5922],\n",
      "          [0.5961, 0.5961, 0.5961,  ..., 0.5922, 0.5922, 0.5922],\n",
      "          ...,\n",
      "          [0.8980, 0.8980, 0.9020,  ..., 0.7961, 0.7961, 0.7961],\n",
      "          [0.8980, 0.8980, 0.9020,  ..., 0.7961, 0.7961, 0.7961],\n",
      "          [0.8980, 0.8980, 0.9020,  ..., 0.7961, 0.7961, 0.7961]],\n",
      "\n",
      "         [[0.6235, 0.6235, 0.6235,  ..., 0.6235, 0.6235, 0.6235],\n",
      "          [0.6235, 0.6235, 0.6235,  ..., 0.6235, 0.6235, 0.6235],\n",
      "          [0.6314, 0.6314, 0.6314,  ..., 0.6275, 0.6275, 0.6275],\n",
      "          ...,\n",
      "          [0.8980, 0.8980, 0.9020,  ..., 0.8471, 0.8471, 0.8471],\n",
      "          [0.8980, 0.8980, 0.9020,  ..., 0.8471, 0.8471, 0.8471],\n",
      "          [0.8980, 0.8980, 0.9020,  ..., 0.8471, 0.8471, 0.8471]],\n",
      "\n",
      "         [[0.5529, 0.5529, 0.5529,  ..., 0.5529, 0.5529, 0.5529],\n",
      "          [0.5569, 0.5569, 0.5569,  ..., 0.5529, 0.5529, 0.5529],\n",
      "          [0.5490, 0.5490, 0.5490,  ..., 0.5451, 0.5451, 0.5451],\n",
      "          ...,\n",
      "          [0.9059, 0.9059, 0.9098,  ..., 0.8784, 0.8784, 0.8784],\n",
      "          [0.9059, 0.9059, 0.9098,  ..., 0.8784, 0.8784, 0.8784],\n",
      "          [0.9059, 0.9059, 0.9098,  ..., 0.8784, 0.8784, 0.8784]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.5961, 0.5922, 0.5922,  ..., 0.5490, 0.5490, 0.5490],\n",
      "          [0.5961, 0.5961, 0.5922,  ..., 0.5490, 0.5490, 0.5490],\n",
      "          [0.6039, 0.6000, 0.6000,  ..., 0.5451, 0.5451, 0.5451],\n",
      "          ...,\n",
      "          [0.1804, 0.1804, 0.1882,  ..., 0.2392, 0.2392, 0.2392],\n",
      "          [0.1804, 0.1804, 0.1804,  ..., 0.2353, 0.2353, 0.2353],\n",
      "          [0.1765, 0.1804, 0.1804,  ..., 0.2353, 0.2353, 0.2353]],\n",
      "\n",
      "         [[0.6000, 0.5961, 0.5961,  ..., 0.5804, 0.5804, 0.5804],\n",
      "          [0.6000, 0.6000, 0.5961,  ..., 0.5804, 0.5804, 0.5804],\n",
      "          [0.6078, 0.6039, 0.6039,  ..., 0.5765, 0.5765, 0.5765],\n",
      "          ...,\n",
      "          [0.1412, 0.1412, 0.1373,  ..., 0.2039, 0.2039, 0.2039],\n",
      "          [0.1412, 0.1412, 0.1412,  ..., 0.2039, 0.2039, 0.2039],\n",
      "          [0.1412, 0.1412, 0.1412,  ..., 0.2078, 0.2078, 0.2078]],\n",
      "\n",
      "         [[0.6196, 0.6157, 0.6157,  ..., 0.5922, 0.5922, 0.5922],\n",
      "          [0.6196, 0.6196, 0.6157,  ..., 0.5922, 0.5922, 0.5922],\n",
      "          [0.6275, 0.6235, 0.6235,  ..., 0.5882, 0.5882, 0.5882],\n",
      "          ...,\n",
      "          [0.1059, 0.1059, 0.1020,  ..., 0.1765, 0.1765, 0.1765],\n",
      "          [0.1059, 0.1059, 0.1059,  ..., 0.1804, 0.1804, 0.1804],\n",
      "          [0.1098, 0.1098, 0.1059,  ..., 0.1843, 0.1843, 0.1843]]],\n",
      "\n",
      "\n",
      "        [[[0.8471, 0.8471, 0.8471,  ..., 0.9412, 0.9412, 0.9412],\n",
      "          [0.8471, 0.8471, 0.8471,  ..., 0.9412, 0.9412, 0.9412],\n",
      "          [0.8510, 0.8510, 0.8510,  ..., 0.9412, 0.9412, 0.9412],\n",
      "          ...,\n",
      "          [0.2000, 0.2000, 0.2039,  ..., 0.2549, 0.2549, 0.2549],\n",
      "          [0.2000, 0.2000, 0.2039,  ..., 0.2549, 0.2549, 0.2549],\n",
      "          [0.2000, 0.2000, 0.2039,  ..., 0.2549, 0.2549, 0.2549]],\n",
      "\n",
      "         [[0.8471, 0.8471, 0.8471,  ..., 0.9412, 0.9412, 0.9412],\n",
      "          [0.8471, 0.8471, 0.8471,  ..., 0.9412, 0.9412, 0.9412],\n",
      "          [0.8510, 0.8510, 0.8510,  ..., 0.9412, 0.9412, 0.9412],\n",
      "          ...,\n",
      "          [0.2000, 0.2000, 0.2039,  ..., 0.2549, 0.2549, 0.2549],\n",
      "          [0.2000, 0.2000, 0.2039,  ..., 0.2549, 0.2549, 0.2549],\n",
      "          [0.2000, 0.2000, 0.2039,  ..., 0.2549, 0.2549, 0.2549]],\n",
      "\n",
      "         [[0.8471, 0.8471, 0.8471,  ..., 0.9412, 0.9412, 0.9412],\n",
      "          [0.8471, 0.8471, 0.8471,  ..., 0.9412, 0.9412, 0.9412],\n",
      "          [0.8510, 0.8510, 0.8510,  ..., 0.9412, 0.9412, 0.9412],\n",
      "          ...,\n",
      "          [0.2000, 0.2000, 0.2039,  ..., 0.2549, 0.2549, 0.2549],\n",
      "          [0.2000, 0.2000, 0.2039,  ..., 0.2549, 0.2549, 0.2549],\n",
      "          [0.2000, 0.2000, 0.2039,  ..., 0.2549, 0.2549, 0.2549]]],\n",
      "\n",
      "\n",
      "        [[[0.8275, 0.8275, 0.8235,  ..., 0.6902, 0.6902, 0.6902],\n",
      "          [0.8275, 0.8235, 0.8235,  ..., 0.6902, 0.6902, 0.6902],\n",
      "          [0.8196, 0.8196, 0.8196,  ..., 0.6902, 0.6902, 0.6902],\n",
      "          ...,\n",
      "          [0.7922, 0.7922, 0.7922,  ..., 0.5804, 0.5804, 0.5804],\n",
      "          [0.7922, 0.7922, 0.7922,  ..., 0.5804, 0.5804, 0.5804],\n",
      "          [0.7922, 0.7922, 0.7922,  ..., 0.5804, 0.5804, 0.5804]],\n",
      "\n",
      "         [[0.8196, 0.8196, 0.8157,  ..., 0.6549, 0.6549, 0.6549],\n",
      "          [0.8196, 0.8157, 0.8157,  ..., 0.6549, 0.6549, 0.6549],\n",
      "          [0.8118, 0.8118, 0.8118,  ..., 0.6549, 0.6549, 0.6549],\n",
      "          ...,\n",
      "          [0.7529, 0.7529, 0.7529,  ..., 0.5373, 0.5373, 0.5373],\n",
      "          [0.7529, 0.7529, 0.7529,  ..., 0.5373, 0.5373, 0.5373],\n",
      "          [0.7529, 0.7529, 0.7529,  ..., 0.5373, 0.5373, 0.5373]],\n",
      "\n",
      "         [[0.8627, 0.8627, 0.8588,  ..., 0.6588, 0.6588, 0.6588],\n",
      "          [0.8627, 0.8588, 0.8588,  ..., 0.6588, 0.6588, 0.6588],\n",
      "          [0.8549, 0.8549, 0.8549,  ..., 0.6588, 0.6588, 0.6588],\n",
      "          ...,\n",
      "          [0.7490, 0.7490, 0.7490,  ..., 0.5216, 0.5216, 0.5216],\n",
      "          [0.7490, 0.7490, 0.7490,  ..., 0.5216, 0.5216, 0.5216],\n",
      "          [0.7490, 0.7490, 0.7490,  ..., 0.5216, 0.5216, 0.5216]]]]), tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]])]\n",
      "Epoch_loss:0.0009464043378829956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:16<00:00,  7.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_loss:0.09158184945583343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../chapter_three/net.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [24], line 62\u001b[0m\n\u001b[0;32m     59\u001b[0m     writer\u001b[39m.\u001b[39mclose()\n\u001b[0;32m     61\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m\u001b[39m==\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m---> 62\u001b[0m     Train()\n",
      "Cell \u001b[1;32mIn [24], line 58\u001b[0m, in \u001b[0;36mTrain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     56\u001b[0m             \u001b[39mif\u001b[39;00m test_loss\u001b[39m<\u001b[39mbest_loss:\n\u001b[0;32m     57\u001b[0m                 best_loss\u001b[39m=\u001b[39mtest_loss\n\u001b[1;32m---> 58\u001b[0m                 torch\u001b[39m.\u001b[39;49msave({\u001b[39m\"\u001b[39;49m\u001b[39mparams\u001b[39;49m\u001b[39m\"\u001b[39;49m:net\u001b[39m.\u001b[39;49mstate_dict(),\u001b[39m\"\u001b[39;49m\u001b[39mloss\u001b[39;49m\u001b[39m\"\u001b[39;49m:test_loss},checkpoint)\n\u001b[0;32m     59\u001b[0m writer\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[1;32md:\\Miniconda3\\envs\\torch\\lib\\site-packages\\torch\\serialization.py:377\u001b[0m, in \u001b[0;36msave\u001b[1;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[0;32m    341\u001b[0m \u001b[39m\"\"\"save(obj, f, pickle_module=pickle, pickle_protocol=DEFAULT_PROTOCOL, _use_new_zipfile_serialization=True)\u001b[39;00m\n\u001b[0;32m    342\u001b[0m \n\u001b[0;32m    343\u001b[0m \u001b[39mSaves an object to a disk file.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    373\u001b[0m \u001b[39m    >>> torch.save(x, buffer)\u001b[39;00m\n\u001b[0;32m    374\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    375\u001b[0m _check_dill_version(pickle_module)\n\u001b[1;32m--> 377\u001b[0m \u001b[39mwith\u001b[39;00m _open_file_like(f, \u001b[39m'\u001b[39;49m\u001b[39mwb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m opened_file:\n\u001b[0;32m    378\u001b[0m     \u001b[39mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[0;32m    379\u001b[0m         \u001b[39mwith\u001b[39;00m _open_zipfile_writer(opened_file) \u001b[39mas\u001b[39;00m opened_zipfile:\n",
      "File \u001b[1;32md:\\Miniconda3\\envs\\torch\\lib\\site-packages\\torch\\serialization.py:231\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    229\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[0;32m    230\u001b[0m     \u001b[39mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 231\u001b[0m         \u001b[39mreturn\u001b[39;00m _open_file(name_or_buffer, mode)\n\u001b[0;32m    232\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    233\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m mode:\n",
      "File \u001b[1;32md:\\Miniconda3\\envs\\torch\\lib\\site-packages\\torch\\serialization.py:212\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, name, mode):\n\u001b[1;32m--> 212\u001b[0m     \u001b[39msuper\u001b[39m(_open_file, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39mopen\u001b[39;49m(name, mode))\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../chapter_three/net.pth'"
     ]
    }
   ],
   "source": [
    "#模型训练\n",
    "import torch\n",
    "from torch import nn,optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tensorboardX import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "import os.path as osp\n",
    "\n",
    "def Train():\n",
    "    net = ResNet18Unet().to(device=device)\n",
    "    trainTrainsform = TrainTrainsform()\n",
    "    trainset = SegmentationData(data_folder,mask_folder,trainTrainsform)\n",
    "    testset = SegmentationData(data_folder,mask_folder,subset=\"test\",trainsform=TestTrainsform())\n",
    "    trainloader = DataLoader(trainset,batch_size=batch_size,shuffle=True,num_workers=0)\n",
    "    print(next(iter(trainloader)))\n",
    "    testloader = DataLoader(testset,batch_size=batch_size,shuffle=True,num_workers=0)\n",
    "    cirteron = nn.CrossEntropyLoss(weight=torch.Tensor([0.3,1.0]).to(device=device))\n",
    "    best_loss = 1e9\n",
    "    if osp.exists(checkpoint):\n",
    "        ckpt = torch.load(checkpoint)\n",
    "        best_loss = ckpt[\"loss\"]\n",
    "        net.load_state_dict(ckpt[\"params\"])\n",
    "        print(\"checkpoint loaded……\")\n",
    "    writer = SummaryWriter(\"logs\")\n",
    "    for n,(num_eopchs,lr) in enumerate(epoch_lr):\n",
    "        optimizer = optim.SGD(net.parameters(),lr=lr,momentum=0.9,weight_decay=5e-3)\n",
    "        for epoch in range(num_eopchs):\n",
    "            net.train()\n",
    "            #pbar = tqdm(enumerate(trainloader),total=len(trainloader))\n",
    "            epoch_loss = 0.0\n",
    "            for i, (img,mask) in enumerate(trainloader):\n",
    "                out = net(img.to(device))\n",
    "                loss = cirteron(out,mask.to(device).long().squeeze(1))\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                if i%10==0:\n",
    "                    #pbar.set_description(\"loss:{}\".format(loss))\n",
    "                    pass\n",
    "                epoch_loss+=loss.item()\n",
    "                print(\"Epoch_loss:{}\".format(epoch_loss/len(trainloader.dataset)))\n",
    "                writer.add_scalar(\"seg_epoch_loss\",epoch_loss/len(trainloader.dataset),sum([e[0] for e in epoch_lr[:n]])+epoch)\n",
    "                with torch.no_grad():\n",
    "                    net.eval()\n",
    "                    test_loss = 0.0\n",
    "                    for i,(img,mask) in tqdm(enumerate(testloader),total=len(testloader)):\n",
    "                        out = net(img.to(device))\n",
    "                        loss = cirteron(out,mask.to(device).long().squeeze(1))\n",
    "                        test_loss+=loss.item()\n",
    "                    print(\"Test_loss:{}\".format(test_loss/len(testloader.dataset)))\n",
    "                    writer.add_scalar(\n",
    "                        \"seg_test_loss\",\n",
    "                        test_loss/len(testloader.dataset),\n",
    "                        sum([e[0] for e in epoch_lr[:n]])+epoch\n",
    "                    )\n",
    "                if test_loss<best_loss:\n",
    "                    best_loss=test_loss\n",
    "                    torch.save({\"params\":net.state_dict(),\"loss\":test_loss},checkpoint)\n",
    "    writer.close()\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    Train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d30c415e52c387ef28d770f1c5e3eb8aa24d6884df82fa2808f92248cea45e8e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
